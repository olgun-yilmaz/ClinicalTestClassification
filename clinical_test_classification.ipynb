{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#NLP\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir('res')",
   "id": "3dac4bd872c6213b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('mtsamples.csv')\n",
    "df.tail()"
   ],
   "id": "147bf90a3ba214be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().sum()",
   "id": "4717e914b7e86f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.drop('Unnamed: 0', axis=1, inplace=True)",
   "id": "d92199c9caae34b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df[df['transcription'].notna()]\n",
    "df.isna().sum()"
   ],
   "id": "1584e07a2c0ccb02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_categories = df.groupby(df['medical_specialty'])\n",
    "\n",
    "i = 0\n",
    "for cat_name, data_category in data_categories:\n",
    "    i += 1\n",
    "    print(f'Category_{i} : {cat_name} : {len(data_category)}')"
   ],
   "id": "cc8c199f31507e17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_data_categories = data_categories.filter(lambda x : x.shape[0] > 50)\n",
    "data_categories = filtered_data_categories.groupby(df['medical_specialty'])\n",
    "\n",
    "i = 0\n",
    "for cat_name, data_category in data_categories:\n",
    "    i += 1\n",
    "    print(f'Category_{i} : {cat_name} : {len(data_category)}')"
   ],
   "id": "79afc884082568d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "sns.countplot(y = 'medical_specialty', data = filtered_data_categories, palette = 'Set2')\n",
    "plt.show()"
   ],
   "id": "9ad6d54828b233c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = filtered_data_categories[['transcription', 'medical_specialty']]\n",
    "data"
   ],
   "id": "7df9cf56bebf015a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.isna().sum()",
   "id": "9966622a9d6b0163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation)) # noktalama isaretlerini kaldir.\n",
    "    \n",
    "    text1 = \"\".join([w for w in text if not w.isdigit()])\n",
    "    \n",
    "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    \n",
    "    text2 = text1.lower()\n",
    "    text2 = replace_by_space_re.sub(\"\", text2)\n",
    "    \n",
    "    return text2"
   ],
   "id": "6cbe22eb1b8075ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lemmatize_text(text):\n",
    "    wordlist = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    initial_sentence = sentences[0:1]\n",
    "    final_sentence = sentences[len(sentences)-2:len(sentences)-1]\n",
    "    \n",
    "    for sentence in initial_sentence:\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            wordlist.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    for sentence in final_sentence:\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            wordlist.append(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(wordlist)"
   ],
   "id": "2528441214534bd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[\"transcription2\"] = data[\"transcription\"].apply(lemmatize_text)\n",
    "data[\"transcription2\"] = data[\"transcription2\"].apply(clean_text)"
   ],
   "id": "cd7856505cdb3e26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "528a648d7c080471",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8e42c93bd485b8e9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
